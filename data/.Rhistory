piiSum<-function(n){
a<-(0:n)
b <- 2*a+1
c <- (-1/3)^a
d <- c/b
e<-sqrt(12)*sum(d)
return (e)
}
#b)
piiSum(1.5)
piiSum(100)
#Tehtävä 7
#
poisbinom<-function(n,p,grid){
plot(grid, dbinom(grid, n, p),
type='h', main = paste("n=", n,", p=", p))
lines(grid, dpois(grid, n*p), col='blue', type='b')
}
poisbinom(n=10, p=0.5, g= 0:10)
#a)
poisbinom(n=100, p=0.1, g= 0:20)
#b)
poisbinom(n=1000, p=0.01, g= 0:20)
#
#Huomataan että jälkimmäisessä kuvaajat osuvat tarkemmin
#kohdilleen, jolloin voimme päätellä että silloin Poisson
#jakauma sopii paremmin binomijakauman approksimointiin
#
#Tehtävä 8
#a)
piiSum<-function(n){
a<-(0:n)
b <- 2*a+1
c <- (-1/3)^a
d <- c/b
e<-sqrt(12)*sum(d)
return (e)
}
#b)
piiSum(1.5)
piiSum(100)
#
#
#Tehtävä 9
#
#Väittely pyörii siis sen ympärillä, kuuluisiko tilastotieteilijöiden sekaantua big datan ja
#big busineksen liittoon. Argumenttina vastaan toimii se että tilastotieteilijöillä on
#ammattiylpeyttä, jonka joutuu myymään kun alkaa tekemään selkoa datasta siksi että yritykset
#voisivat nyhtää enemmän rahaa. On myös puhe siitä että big data saattaa olla vain hetken
#huumaa. Toisessa artikkelissa huomautetaan, kuinka esimerkiksi googlen haku algoritmin
#taustalla piilee tilastotiedettä ja että google muuten ajaa data suuntautunutta tekemistä.
#Verrataan myös erilaisia tilanteita, ja todetaan että tietoa ei haluta heittää pois, sillä
#saatetaan tarvita joku päivä, mutta toisaalta kaiken säilöminen on hyvin epätehokasta. Lopuksi
#todetaan että tilastotieteen etäisyys big dataan johtuu sen erilaisesta lähestymistavasta siihen
#verrattuna tietojenkäsittelytieteeseen.
#
#Tehtävä 10
#
#Koneoppimisessa voidaan hyödyntää matematiikkaa, tilastotiedettä ja tietojenkäsittelytiedettä.
#Koneoppimisen tarkoituksena on hyödyntää taustatietoa ja tulevaa syötettä luodakseen parempia
#tekoälyjä. Äly tai kone niin sanotusti oppii, ja pystyy siksi vastaamaan paremmin.
#
#Yllätyin siitä kuinka simppeli funktio suodattimen takana on, mutta että se on silti niin
#tarkka. Ylipäätänsä on yllättävää miten paljon todennäköisyysmallinnuksia on tuttujen
#toimintoja taustalla. Epäilen kuitenkin että voiko prosentti olla noin korkea, mutta
#toisaalta sanat joiden perusteella sana merkitään roskaksi on sen verran tarkasti valittu,
#ettei se kuitenkaan ole ihan mahdoton ajatus.
#
#Stokastinen päivitysstrategia vaikutti tutulta idealta, sen perusteella mikä toimii,
#koitetaan toistamaan. Luodaan tavallaan tilannerekisteri. Mutta ongelmana tosiaan tulee
#uudet tilanteet, jolloin kone ei osaa vielä reagoida tilanteisiin, kuten pingis videossa
#huomattiin. Olen vieläkin skeptinen kyseisen videon suhteen, sillä ottelu vaikutti enemmänkin
#filmatisoidulta kuin aidolta pelitilanteelta. Idea taustalla on kylläkin ihan logiinen, video
#vain vaikutti liiankin elokuvamaiselta, joka taas vie minusta uskottavuutta, mikä ehkä
#olikin tarkoitus videolla.
#Robotin palkitseminen kuulostaa käsitteenä hauskalta, vähän niin kuin koiraa palkitaan
#hyvästä käytöksestä, mutta koska robotti on ohjelmoitu, mikä toimii oikein sen motivaattorina.
#Siinäpä vasta mietittävää, millainen tekoäly olisi kyseessä.
a<-(129,134,142,114,120,116,133,142,138,148,129,133,141)
a<-c(129,134,142,114,120,116,133,142,138,148,129,133,141)
mean(a)
sd(a)
b<-a-mean(a)
sum(b)
sum(b)/13
sum(a)
b^2
b<-b^2
sum(b)
sum(b)/13
sd(a)
sum(b)/13
c<-sum(b)/13
sqrt(c)
sd(a)
mean(a)
c<-sum(b)
c<-c/13
sqrt(c)
c<-c/12
a<-c(129,134,142,114,120,116,133,142,138,148,129,133,141)
mean(a)
b<-a-mean(a)
b<-b^2
c<-sum(b)
c<-c/12
sqrt(c)
sd(a)
b<-a-mean(a)
b<-b^2
c<-sum(b)
c<-c/12
sqrt(c)
c<-c/12
a<-c(129,134,142,114,120,116,133,142,138,148,129,133,141)
mean(a)
b<-a-mean(a)
b<-b^2
c<-sum(b)
c<-c/12
sqrt(c)
sd(a)
A<-c(37,42,51,39,44,48,29)
mean(A)
sd(A)
A<-c(37,42,51,39,44,48,29)
mean(A)
B<-A-mean(A)
B<-B^2
C<-sum(B)
C<-C/6
sqrt(c)
sd(A)
A<-c(37,42,51,39,44,48,29)
mean(A)
B<-A-mean(A)
B<-B^2
C<-sum(B)
C<-C/6
sqrt(c)
C<-C/7
A<-c(37,42,51,39,44,48,29)
mean(A)
B<-A-mean(A)
B<-B^2
C<-sum(B)
C<-C/6
sqrt(c)
sd(A)
A<-c(37,42,51,39,44,48,29)
mean(A)
B<-A-mean(A)
B<-B^2
C<-sum(B)
C<-C/6
sqrt(C)
sd(A)
A<-c(37,42,51,39,44,48,29)
mean(A)
B<-A-mean(A)
B<-B^2
C<-sum(B)
C<-C/6
sqrt(C)
qt(0.025,19)
qt(0.005,19)
qt(0.025,6)
qt(0.005,6)
#Tiltu viikko 6
#
#Tehtävä 7
#a)
#
#b)
a<-c()
tconfint <- function(xbar,s,n,q){
a<-xbar+qt(q,n-1)*(s/sqrt(n))
b<-xbar-qt(q,n-1)*(s/sqrt(n))
return (a,b)
}
tconfint(330.2,15.4,20,0.025)
tconfint <- function(xbar,s,n,q){
a<-xbar+qt(q,n-1)*(s/sqrt(n))
b<-xbar-qt(q,n-1)*(s/sqrt(n))
C<-c(a,b)
return C
}
#b)
tconfint(330.2,15.4,20,0.025)
tconfint <- function(xbar,s,n,q){
a<-xbar+qt(q,n-1)*(s/sqrt(n))
b<-xbar-qt(q,n-1)*(s/sqrt(n))
C<-c(a,b)
return(C)
}
#b)
tconfint(330.2,15.4,20,0.025)
tconfint(330.2,15.4,20,0.005)
x<-rnorm(10)
ci<-t.test(x)$conf.int
lower[1]<-ci[1]
upper[1]<-ci[2]
lower<-c(length(100))
upper<-c(length(100))
x<-rnorm(10)
ci<-t.test(x)$conf.int
lower[1]<-ci[1]
upper[1]<-ci[2]
lower<-c(length(100))
upper<-c(length(100))
for(i in 1:100){
x<-rnorm(10)
ci<-t.test(x)$conf.int
lower[i]<-ci[1]
upper[i]<-ci[2]
}
upper[100]
lower[100]
xlims<-c(min(lower),max(upper))
plot(NULL, xlim=xlims, ylim = c(1,100))
segments(lower, 1:100, upper, 1:100,
col=ifelse(lower>0|upper<0,'red','black'))
abline(v=0)
a<-c(8.30, 8.42, 8.44, 8.32, 8.43, 8.41, 8.42, 8.46, 8.37, 8.42)
ave(a)
a
sum(a)
sum(a)/length(a)
pnorm(-0,0632)
pnorm(0,0632)
pnorm(-0.0632)
1-pnorm(-0.0632)
1-pnorm(0.0632)
pnorm(0.0632)
pnorm(0.001)
pnorm(4.4722)
pnorm(-0,0632, 8.4, 0.05)
pnorm(8.399, 8.4, 0.05/sqrt(10))
1-pnorm(8.399, 8.4, 0.05/sqrt(10))
pnorm(2.24)
pnorm(1.49)
pnorm(0.0632)
pnorm(0.06319)
pnorm(0.0631)
pnorm(0.00631)
pnorm(0.06)
pnorm(-0.06)
qt(35,0.005)
qt(0.005,35)
qt(0.99,35)
qt(0.05,35)
qt(0.05,11)
qt(0.95,11)
qt(0.95,7)
qt(0.05,7)
qt(0.025,7)
qt(0.005,7)
qt(0.095,7)
qt(0.95,7)
qt(0.025,7)
qt(0.005,7)
qt(0.005,35)
qt(0.025,35)
pbinom(27)
pbinom(27, 6,7)
pbinom(27, 6.7)
pnorm(q = 27, mean = 6.7, sd = 6.7)
pnorm(2.955)
1-p(2.9552)
1-pnorm(2.9552)
1-pnorm(2.955)
var->c(4,2,-5,3,6,4,-5,-2)
v->c(4,2,-5,3,6,4,-5,-2)
v<-c(4,2,-5,3,6,4,-5,-2)
mean(v)
ennen<-c(134,122,118,130,144,125,127,133)
jalkeen<-c(130,120,123,127,138,121,132,135)
ennen-jalkeen
mean(ennen)-mean(jalkeen)
var(v)
v
var(v)
/7
var(v)/7
s<-v-mean(v)
s<-s^2
sum(s)/7
sqrt(var(v))
qt(7, 0.05)
qt(0.05, 7)
pnorm(0.374)
pnorm(0.38)
pnorm(0.38, lower.tail = TRUE)
pnorm(0.38, lower.tail = FALSE)
pnorm(0.38, lower.tail = FALSE)
pnorm(0.38, lower.tail = FALSE)*2
pnorm(0.374, lower.tail = FALSE)
pnorm(0.374, lower.tail = FALSE)*2
1-pf(2.33, 2,33)
1-pf(0.63, 3,3,42)
days<-c(156,144,170,158,172,148,152)
sum(days)
sum(days)/7
mean<-sum(days)/length(days)
days-mean
days<-days-mean
days<-days^2
days<-days/mean
days<-sum(days)
myfun <- function(k){
setwd(k)
library(Matrix)
library(ggplot2)
library(dplyr)
}
myfun("/Users/veikko/Desktop/datakurssi/IODS-project/data")
getwd()
lrn14 <- read.table("JYTOPKYS3-data.txt", header = T, sep = "\t")
str(lrn14)
dim(lrn14)
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
colnames(lrn14)[57] <- "age"
colnames(lrn14)[58] <- "attitude"
colnames(lrn14)[59] <- "points"
varsToGet <- c("gender", "age", "attitude", "deep", "stra", "surf", "points")
new_lrn14 <- select(lrn14, one_of(varsToGet))
new_lrn14 <- filter(new_lrn14, points > 0)
setwd("/Users/veikko/Desktop/datakurssi/IODS-project")
getwd()
write.csv(new_lrn14, file = "learning2014.csv", sep = ",")
learning2014 <- read.csv("learning2014.csv", sep = ",", header = T)
learning2014 <- learning2014[-1]
str(learning2014)
head(learning2014)
learning2014$attitude <- learning2014$attitude / 10
head(learning2014)
str(learning2014)
summary(learning2014)
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",sep="\t", header=TRUE)
str(lrn14)
dim(lrn14)
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
colnames(lrn14)[57] <- "age"
colnames(lrn14)[58] <- "attitude"
colnames(lrn14)[59] <- "points"
varsToGet <- c("gender", "age", "attitude", "deep", "stra", "surf", "points")
new_lrn14 <- select(lrn14, one_of(varsToGet))
new_lrn14 <- filter(new_lrn14, points > 0)
setwd("/Users/veikko/Desktop/datakurssi/IODS-project")
getwd()
write.csv(new_lrn14, file = "learning2014.csv", sep = ",")
learning2014 <- read.csv("learning2014.csv", sep = ",", header = T)
learning2014 <- learning2014[-1]
str(learning2014)
head(learning2014)
learning2014$attitude <- learning2014$attitude / 10
head(learning2014)
str(learning2014)
summary(learning2014)
library(Matrix)
library(ggplot2)
library(dplyr)
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",sep="\t", header=TRUE)
str(lrn14)
dim(lrn14)
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
colnames(lrn14)[57] <- "age"
colnames(lrn14)[58] <- "attitude"
colnames(lrn14)[59] <- "points"
varsToGet <- c("gender", "age", "attitude", "deep", "stra", "surf", "points")
new_lrn14 <- select(lrn14, one_of(varsToGet))
new_lrn14 <- filter(new_lrn14, points > 0)
setwd("/Users/veikko/Desktop/datakurssi/IODS-project")
getwd()
write.csv(new_lrn14, file = "learning2014.csv", sep = ",")
learning2014 <- read.csv("learning2014.csv", sep = ",", header = T)
learning2014 <- learning2014[-1]
str(learning2014)
head(learning2014)
learning2014$attitude <- learning2014$attitude / 10
head(learning2014)
str(learning2014)
summary(learning2014)
View(new_lrn14)
getwd()
#Jonas Harjunpää 27.01.2016
#This file contains the wrangled data
learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",sep="\t", header=TRUE)
dim(learning2014)
str(learning2014)
#dim outputs 184 and 60, as in observations and variables
#str outputs each variable, how many levels and what the values where
learning2014$attitude <- learning2014$Attitude/10
library(dplyr)
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D07","D14","D22","D30")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
deep_columns <- select(learning2014, one_of(deep_questions))
learning2014$deep <- rowMeans(deep_columns)
surface_columns <-select(learning2014, one_of(surface_questions))
learning2014$surf <- rowMeans(surface_columns)
strategic_columns <- select(learning2014, one_of(strategic_questions))
learning2014$stra <- rowMeans(strategic_columns)
keep_columns <- c("gender","Age","attitude", "deep", "stra", "surf", "Points")
learning2014 <- select(learning2014, one_of(keep_columns))
colnames(learning2014)[2] <- "age"
colnames(learning2014)[7] <- "points"
learning2014<-filter(learning2014, points > 0)
write.csv(learning2014, file = "learning2014.csv", row.names=FALSE)
lrn2014 <- read.csv("learning2014.csv")
str(lrn2014)
head(lrn2014)
clear()
clear
getwd()
setwd(C:\Users\Jonas\Documents\GitHub\IODS-project\data\)
setwd("C:\Users\Jonas\Documents\GitHub\IODS-project\data\")
setwd("C:/Users/Jonas/Documents/GitHub/IODS-project/data")
getwd()
#Jonas Harjunpää 04.02.2017
#This file contains the wrangled data of a study about student alcohol consumpiton
#from here https://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION
setwd("C:/Users/Jonas/Documents/GitHub/IODS-project/data")
getwd()
# read the math class questionaire data into memory
math <- read.csv("student-mat.csv", sep = ";" , header=TRUE)
# read the portuguese class questionaire data into memory
por <- read.csv("student-por.csv", sep = ";", header = TRUE)
# look at the structure and dimensions of both data
str(math)
dim(math)
str(por)
dim(por)
#Jonas Harjunpää 04.02.2017
#This file contains the wrangled data of a study about student alcohol consumpiton
#from here https://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION
setwd("C:/Users/Jonas/Documents/GitHub/IODS-project/data")
getwd()
# read the math class questionaire data into memory
math <- read.csv("student-mat.csv", sep = ";" , header=TRUE)
# read the portuguese class questionaire data into memory
por <- read.csv("student-por.csv", sep = ";", header = TRUE)
# look at the structure and dimensions of both data
str(math)
dim(math)
str(por)
dim(por)
library(dplyr)
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet")
math_por <- inner_join(math, por, by = join_by, suffix=c(".math",".por"))
str(math_por)
dim(math_por)
alc <- select(math_por, one_of(join_by))
notjoined_columns <- colnames(math)[!colnames(math) %in% join_by]
notjoined_columns
for(column_name in notjoined_columns) {
two_columns <- select(math_por, starts_with(column_name))
first_column <- select(two_columns, 1)[[1]]
if(is.numeric(first_column)) {
alc[column_name] <- round(rowMeans(two_columns))
} else { # else if it's not numeric...
alc[column_name] <- first_column
}
}
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)
alc <- mutate(alc, high_use = alc_use > 2)
glimpse(alc)
write.csv(learning2014, file = "alc.csv", row.names=FALSE)
alc2 <- read.csv("alc.csv")
str(alc2)
head(alc2)
write.csv(alc, file = "alc.csv", row.names=FALSE)
alc2 <- read.csv("alc.csv")
str(alc2)
head(alc2)
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt",sep=",", header=TRUE)
colnames(alc)
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt",sep=",", header=TRUE)
colnames(alc)
