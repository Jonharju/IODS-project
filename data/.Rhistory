poisbinom(n=100, p=0.1, g= 0:20)
#b)
poisbinom(n=1000, p=0.01, g= 0:20)
#
#Huomataan että jälkimmäisessä kuvaajat osuvat tarkemmin
#kohdilleen, jolloin voimme päätellä että silloin Poisson
#jakauma sopii paremmin binomijakauman approksimointiin
#
#Tehtävä 8
#a)
piiSum<-function(n){
a<-(0:n)
b <- 2*a+1
c <- (-1/3)^a
d <- c/b
e<-sqrt(12)*sum(d)
return (e)
}
#b)
piiSum(1.5)
piiSum(100)
#
#
#Tehtävä 9
#
#Väittely pyörii siis sen ympärillä, kuuluisiko tilastotieteilijöiden sekaantua big datan ja
#big busineksen liittoon. Argumenttina vastaan toimii se että tilastotieteilijöillä on
#ammattiylpeyttä, jonka joutuu myymään kun alkaa tekemään selkoa datasta siksi että yritykset
#voisivat nyhtää enemmän rahaa. On myös puhe siitä että big data saattaa olla vain hetken
#huumaa. Toisessa artikkelissa huomautetaan, kuinka esimerkiksi googlen haku algoritmin
#taustalla piilee tilastotiedettä ja että google muuten ajaa data suuntautunutta tekemistä.
#Verrataan myös erilaisia tilanteita, ja todetaan että tietoa ei haluta heittää pois, sillä
#saatetaan tarvita joku päivä, mutta toisaalta kaiken säilöminen on hyvin epätehokasta. Lopuksi
#todetaan että tilastotieteen etäisyys big dataan johtuu sen erilaisesta lähestymistavasta siihen
#verrattuna tietojenkäsittelytieteeseen.
#
#Tehtävä 10
#
#Koneoppimisessa voidaan hyödyntää matematiikkaa, tilastotiedettä ja tietojenkäsittelytiedettä.
#Koneoppimisen tarkoituksena on hyödyntää taustatietoa ja tulevaa syötettä luodakseen parempia
#tekoälyjä. Äly tai kone niin sanotusti oppii, ja pystyy siksi vastaamaan paremmin.
#
#Yllätyin siitä kuinka simppeli funktio suodattimen takana on, mutta että se on silti niin
#tarkka. Ylipäätänsä on yllättävää miten paljon todennäköisyysmallinnuksia on tuttujen
#toimintoja taustalla. Epäilen kuitenkin että voiko prosentti olla noin korkea, mutta
#toisaalta sanat joiden perusteella sana merkitään roskaksi on sen verran tarkasti valittu,
#ettei se kuitenkaan ole ihan mahdoton ajatus.
#
#Stokastinen päivitysstrategia vaikutti tutulta idealta, sen perusteella mikä toimii,
#koitetaan toistamaan. Luodaan tavallaan tilannerekisteri. Mutta ongelmana tosiaan tulee
#uudet tilanteet, jolloin kone ei osaa vielä reagoida tilanteisiin, kuten pingis videossa
#huomattiin. Olen vieläkin skeptinen kyseisen videon suhteen, sillä ottelu vaikutti enemmänkin
#filmatisoidulta kuin aidolta pelitilanteelta. Idea taustalla on kylläkin ihan logiinen, video
#vain vaikutti liiankin elokuvamaiselta, joka taas vie minusta uskottavuutta, mikä ehkä
#olikin tarkoitus videolla.
#Robotin palkitseminen kuulostaa käsitteenä hauskalta, vähän niin kuin koiraa palkitaan
#hyvästä käytöksestä, mutta koska robotti on ohjelmoitu, mikä toimii oikein sen motivaattorina.
#Siinäpä vasta mietittävää, millainen tekoäly olisi kyseessä.
a<-(129,134,142,114,120,116,133,142,138,148,129,133,141)
a<-c(129,134,142,114,120,116,133,142,138,148,129,133,141)
mean(a)
sd(a)
b<-a-mean(a)
sum(b)
sum(b)/13
sum(a)
b^2
b<-b^2
sum(b)
sum(b)/13
sd(a)
sum(b)/13
c<-sum(b)/13
sqrt(c)
sd(a)
mean(a)
c<-sum(b)
c<-c/13
sqrt(c)
c<-c/12
a<-c(129,134,142,114,120,116,133,142,138,148,129,133,141)
mean(a)
b<-a-mean(a)
b<-b^2
c<-sum(b)
c<-c/12
sqrt(c)
sd(a)
b<-a-mean(a)
b<-b^2
c<-sum(b)
c<-c/12
sqrt(c)
c<-c/12
a<-c(129,134,142,114,120,116,133,142,138,148,129,133,141)
mean(a)
b<-a-mean(a)
b<-b^2
c<-sum(b)
c<-c/12
sqrt(c)
sd(a)
A<-c(37,42,51,39,44,48,29)
mean(A)
sd(A)
A<-c(37,42,51,39,44,48,29)
mean(A)
B<-A-mean(A)
B<-B^2
C<-sum(B)
C<-C/6
sqrt(c)
sd(A)
A<-c(37,42,51,39,44,48,29)
mean(A)
B<-A-mean(A)
B<-B^2
C<-sum(B)
C<-C/6
sqrt(c)
C<-C/7
A<-c(37,42,51,39,44,48,29)
mean(A)
B<-A-mean(A)
B<-B^2
C<-sum(B)
C<-C/6
sqrt(c)
sd(A)
A<-c(37,42,51,39,44,48,29)
mean(A)
B<-A-mean(A)
B<-B^2
C<-sum(B)
C<-C/6
sqrt(C)
sd(A)
A<-c(37,42,51,39,44,48,29)
mean(A)
B<-A-mean(A)
B<-B^2
C<-sum(B)
C<-C/6
sqrt(C)
qt(0.025,19)
qt(0.005,19)
qt(0.025,6)
qt(0.005,6)
#Tiltu viikko 6
#
#Tehtävä 7
#a)
#
#b)
a<-c()
tconfint <- function(xbar,s,n,q){
a<-xbar+qt(q,n-1)*(s/sqrt(n))
b<-xbar-qt(q,n-1)*(s/sqrt(n))
return (a,b)
}
tconfint(330.2,15.4,20,0.025)
tconfint <- function(xbar,s,n,q){
a<-xbar+qt(q,n-1)*(s/sqrt(n))
b<-xbar-qt(q,n-1)*(s/sqrt(n))
C<-c(a,b)
return C
}
#b)
tconfint(330.2,15.4,20,0.025)
tconfint <- function(xbar,s,n,q){
a<-xbar+qt(q,n-1)*(s/sqrt(n))
b<-xbar-qt(q,n-1)*(s/sqrt(n))
C<-c(a,b)
return(C)
}
#b)
tconfint(330.2,15.4,20,0.025)
tconfint(330.2,15.4,20,0.005)
x<-rnorm(10)
ci<-t.test(x)$conf.int
lower[1]<-ci[1]
upper[1]<-ci[2]
lower<-c(length(100))
upper<-c(length(100))
x<-rnorm(10)
ci<-t.test(x)$conf.int
lower[1]<-ci[1]
upper[1]<-ci[2]
lower<-c(length(100))
upper<-c(length(100))
for(i in 1:100){
x<-rnorm(10)
ci<-t.test(x)$conf.int
lower[i]<-ci[1]
upper[i]<-ci[2]
}
upper[100]
lower[100]
xlims<-c(min(lower),max(upper))
plot(NULL, xlim=xlims, ylim = c(1,100))
segments(lower, 1:100, upper, 1:100,
col=ifelse(lower>0|upper<0,'red','black'))
abline(v=0)
a<-c(8.30, 8.42, 8.44, 8.32, 8.43, 8.41, 8.42, 8.46, 8.37, 8.42)
ave(a)
a
sum(a)
sum(a)/length(a)
pnorm(-0,0632)
pnorm(0,0632)
pnorm(-0.0632)
1-pnorm(-0.0632)
1-pnorm(0.0632)
pnorm(0.0632)
pnorm(0.001)
pnorm(4.4722)
pnorm(-0,0632, 8.4, 0.05)
pnorm(8.399, 8.4, 0.05/sqrt(10))
1-pnorm(8.399, 8.4, 0.05/sqrt(10))
pnorm(2.24)
pnorm(1.49)
pnorm(0.0632)
pnorm(0.06319)
pnorm(0.0631)
pnorm(0.00631)
pnorm(0.06)
pnorm(-0.06)
qt(35,0.005)
qt(0.005,35)
qt(0.99,35)
qt(0.05,35)
qt(0.05,11)
qt(0.95,11)
qt(0.95,7)
qt(0.05,7)
qt(0.025,7)
qt(0.005,7)
qt(0.095,7)
qt(0.95,7)
qt(0.025,7)
qt(0.005,7)
qt(0.005,35)
qt(0.025,35)
pbinom(27)
pbinom(27, 6,7)
pbinom(27, 6.7)
pnorm(q = 27, mean = 6.7, sd = 6.7)
pnorm(2.955)
1-p(2.9552)
1-pnorm(2.9552)
1-pnorm(2.955)
var->c(4,2,-5,3,6,4,-5,-2)
v->c(4,2,-5,3,6,4,-5,-2)
v<-c(4,2,-5,3,6,4,-5,-2)
mean(v)
ennen<-c(134,122,118,130,144,125,127,133)
jalkeen<-c(130,120,123,127,138,121,132,135)
ennen-jalkeen
mean(ennen)-mean(jalkeen)
var(v)
v
var(v)
/7
var(v)/7
s<-v-mean(v)
s<-s^2
sum(s)/7
sqrt(var(v))
qt(7, 0.05)
qt(0.05, 7)
pnorm(0.374)
pnorm(0.38)
pnorm(0.38, lower.tail = TRUE)
pnorm(0.38, lower.tail = FALSE)
pnorm(0.38, lower.tail = FALSE)
pnorm(0.38, lower.tail = FALSE)*2
pnorm(0.374, lower.tail = FALSE)
pnorm(0.374, lower.tail = FALSE)*2
1-pf(2.33, 2,33)
1-pf(0.63, 3,3,42)
days<-c(156,144,170,158,172,148,152)
sum(days)
sum(days)/7
mean<-sum(days)/length(days)
days-mean
days<-days-mean
days<-days^2
days<-days/mean
days<-sum(days)
install.packages("corrplot")
install.packages("tidyverse")
sBoston2 <- scale(Boston)
dist_eu <- dist(Boston2)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
str(gii)
dim(gii)
summary(hd)
summary(gii)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
str(gii)
dim(gii)
summary(hd)
summary(gii)
colnames(hd)[1:8] <- c("HDI_r", "Country", "HDI", "Life_exp", "Edu_exp", "Edu_mean", "GNI", "GNI-HDI")
colnames(gii)[1:10] <- c("GII_r", "Country", "GII", "Mat_deaths", "Young_births", "Parl_seats", "High_edu_f", "High_edu_m", "F_working", "M_working")
library(dplyr)
gii <- mutate(gii, High_edu_f_m = High_edu_f / High_edu_m)
gii <- mutate(gii, F_m_working = F_working / M_working)
human <- inner_join(hd, gii, by = "Country")
write.csv(humanfile = "human.csv", row.names=FALSE)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
str(gii)
dim(gii)
summary(hd)
summary(gii)
colnames(hd)[1:8] <- c("HDI_r", "Country", "HDI", "Life_exp", "Edu_exp", "Edu_mean", "GNI", "GNI-HDI")
colnames(gii)[1:10] <- c("GII_r", "Country", "GII", "Mat_deaths", "Young_births", "Parl_seats", "High_edu_f", "High_edu_m", "F_working", "M_working")
library(dplyr)
gii <- mutate(gii, High_edu_f_m = High_edu_f / High_edu_m)
gii <- mutate(gii, F_m_working = F_working / M_working)
human <- inner_join(hd, gii, by = "Country")
write.csv(human, file = "human.csv", row.names=FALSE)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
str(gii)
dim(gii)
summary(hd)
summary(gii)
colnames(hd)[1:8] <- c("HDI_r", "Country", "HDI", "Life_exp", "Edu_exp", "Edu_mean", "GNI", "GNI-HDI")
colnames(gii)[1:10] <- c("GII_r", "Country", "GII", "Mat_deaths", "Young_births", "Parl_seats", "High_edu_f", "High_edu_m", "F_working", "M_working")
library(dplyr)
gii <- mutate(gii, High_edu_f_m = High_edu_f / High_edu_m)
gii <- mutate(gii, F_m_working = F_working / M_working)
human <- inner_join(hd, gii, by = "Country")
write.csv(human, file = "human.csv", row.names=FALSE)
getwd()
setwd("C:/Users/Jonas/Documents/GitHub/IODS-project/data")
getwd()
write.csv(human, file = "human.csv", row.names=FALSE)
human$GNI <- str_replace(human$GNI, pattern=",", replace ="") %>% as.numeric()
human <- mutate(human, GNI = as.numeric(human$GNI))
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
str(gii)
dim(gii)
summary(hd)
summary(gii)
colnames(hd)[1:8] <- c("HDI_r", "Country", "HDI", "Life_exp", "Edu_exp", "Edu_mean", "GNI", "GNI-HDI")
colnames(gii)[1:10] <- c("GII_r", "Country", "GII", "Mat_deaths", "Young_births", "Parl_seats", "High_edu_f", "High_edu_m", "F_working", "M_working")
library(dplyr)
gii <- mutate(gii, High_edu_f_m = High_edu_f / High_edu_m)
gii <- mutate(gii, F_m_working = F_working / M_working)
human <- inner_join(hd, gii, by = "Country")
write.csv(human, file = "human.csv", row.names=FALSE)
#The second part starts here
human <- mutate(human, GNI = as.numeric(human$GNI))
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
str(gii)
dim(gii)
summary(hd)
summary(gii)
colnames(hd)[1:8] <- c("HDI_r", "Country", "HDI", "Life_exp", "Edu_exp", "Edu_mean", "GNI", "GNI-HDI")
colnames(gii)[1:10] <- c("GII_r", "Country", "GII", "Mat_deaths", "Young_births", "Parl_seats", "High_edu_f", "High_edu_m", "F_working", "M_working")
library(dplyr)
gii <- mutate(gii, High_edu_f_m = High_edu_f / High_edu_m)
gii <- mutate(gii, F_m_working = F_working / M_working)
human <- inner_join(hd, gii, by = "Country")
human <- read.csv("human.csv", sep=",", header= T)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
str(gii)
dim(gii)
summary(hd)
summary(gii)
colnames(hd)[1:8] <- c("HDI_r", "Country", "HDI", "Life_exp", "Edu_exp", "Edu_mean", "GNI", "GNI-HDI")
colnames(gii)[1:10] <- c("GII_r", "Country", "GII", "Mat_deaths", "Young_births", "Parl_seats", "High_edu_f", "High_edu_m", "F_working", "M_working")
library(dplyr)
gii <- mutate(gii, High_edu_f_m = High_edu_f / High_edu_m)
gii <- mutate(gii, F_m_working = F_working / M_working)
human <- inner_join(hd, gii, by = "Country")
write.csv(human, file = "human.csv", row.names=FALSE)
human <- read.csv("human.csv", sep=",", header= T)
#The second part starts here
human <- mutate(human, GNI = as.numeric(human$GNI))
human <- mutate(human, GNI = as.numeric(human$GNI))
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
str(gii)
dim(gii)
summary(hd)
summary(gii)
colnames(hd)[1:8] <- c("HDI_r", "Country", "HDI", "Life_exp", "Edu_exp", "Edu_mean", "GNI", "GNI-HDI")
colnames(gii)[1:10] <- c("GII_r", "Country", "GII", "Mat_deaths", "Young_births", "Parl_seats", "High_edu_f", "High_edu_m", "F_working", "M_working")
library(dplyr)
gii <- mutate(gii, High_edu_f_m = High_edu_f / High_edu_m)
gii <- mutate(gii, F_m_working = F_working / M_working)
human <- inner_join(hd, gii, by = "Country")
write.csv(human, file = "human.csv", row.names=FALSE)
human <- read.csv("human.csv", sep=",", header= T)
human <- mutate(human, GNI = as.numeric(human$GNI))
keep_columns <- c("Country", "High_edu_f_m", "F_m_working", "Edu_exp", "Life_exp", "GNI", "Mat_deaths", "Young_births", "Parl_seats")
human <- select(human, one_of(keep_columns))
human <- read.csv("human.csv", sep=",", header= T)
human <- mutate(human, GNI = as.numeric(human$GNI))
complete.cases(human)
data.frame(human[-1], comp = complete.cases(human))
human <- filter(human, complete.cases(human))
complete.cases(human)
human <- read.csv("human.csv", sep=",", header= T)
#The second part starts here
human <- mutate(human, GNI = as.numeric(human$GNI))
keep_columns <- c("Country", "High_edu_f_m", "F_m_working", "Edu_exp", "Life_exp", "GNI", "Mat_deaths", "Young_births", "Parl_seats")
human <- select(human, one_of(keep_columns))
complete.cases(human)
data.frame(human[-1], comp = complete.cases(human))
human <- filter(human, complete.cases(human))
complete.cases(human)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
str(gii)
dim(gii)
summary(hd)
summary(gii)
colnames(hd)[1:8] <- c("HDI_r", "Country", "HDI", "Life_exp", "Edu_exp", "Edu_mean", "GNI", "GNI-HDI")
colnames(gii)[1:10] <- c("GII_r", "Country", "GII", "Mat_deaths", "Young_births", "Parl_seats", "High_edu_f", "High_edu_m", "F_working", "M_working")
library(dplyr)
gii <- mutate(gii, High_edu_f_m = High_edu_f / High_edu_m)
gii <- mutate(gii, F_m_working = F_working / M_working)
human <- inner_join(hd, gii, by = "Country")
write.csv(human, file = "human.csv", row.names=FALSE)
human <- read.csv("human.csv", sep=",", header= T)
#The second part starts here
human <- mutate(human, GNI = as.numeric(human$GNI))
keep_columns <- c("Country", "High_edu_f_m", "F_m_working", "Edu_exp", "Life_exp", "GNI", "Mat_deaths", "Young_births", "Parl_seats")
human <- select(human, one_of(keep_columns))
complete.cases(human)
data.frame(human[-1], comp = complete.cases(human))
human <- filter(human, complete.cases(human))
complete.cases(human)
View(human)
last <- nrow(human) - 7
last
human <- read.csv("human.csv", sep=",", header= T)
#The second part starts here
human <- mutate(human, GNI = as.numeric(human$GNI))
keep_columns <- c("Country", "High_edu_f_m", "F_m_working", "Edu_exp", "Life_exp", "GNI", "Mat_deaths", "Young_births", "Parl_seats")
human <- select(human, one_of(keep_columns))
data.frame(human[-1], comp = complete.cases(human))
human <- filter(human, complete.cases(human))
human <- human[1:155, ]
rownames(human) <- human$Country
human <- dplyr::select(human, -Country)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
str(gii)
dim(gii)
summary(hd)
summary(gii)
colnames(hd)[1:8] <- c("HDI_r", "Country", "HDI", "Life_exp", "Edu_exp", "Edu_mean", "GNI", "GNI-HDI")
colnames(gii)[1:10] <- c("GII_r", "Country", "GII", "Mat_deaths", "Young_births", "Parl_seats", "High_edu_f", "High_edu_m", "F_working", "M_working")
library(dplyr)
gii <- mutate(gii, High_edu_f_m = High_edu_f / High_edu_m)
gii <- mutate(gii, F_m_working = F_working / M_working)
human <- inner_join(hd, gii, by = "Country")
write.csv(human, file = "human.csv", row.names=FALSE)
human <- read.csv("human.csv", sep=",", header= T)
#The second part starts here
human <- mutate(human, GNI = as.numeric(human$GNI))
keep_columns <- c("Country", "High_edu_f_m", "F_m_working", "Edu_exp", "Life_exp", "GNI", "Mat_deaths", "Young_births", "Parl_seats")
human <- select(human, one_of(keep_columns))
data.frame(human[-1], comp = complete.cases(human))
human <- filter(human, complete.cases(human))
human <- human[1:155, ]
rownames(human) <- human$Country
human <- dplyr::select(human, -Country)
write.csv(human, file = "human.csv", row.names = FALSE)
getwd()
install.packages("FactoMineR")
install.packages("FactoMineR")
install.packages("FactoMineR")
install.packages("FactoMineR")
install.package(minqa)
install.packages("digest")
library(installr)
updateR()
install.packages("installr")
library(installr)
updateR()
